<!doctype html>
<html data-n-head-ssr>
  <head>
    <title>opencvExample | examples | ofDocs</title><meta data-n-head="ssr" data-hid="description" name="description" content="openFrameworks documentation and examples browser"><meta data-n-head="ssr" data-hid="keyword" name="keyword" content=""><meta data-n-head="ssr" property="og:description" content="openFrameworks documentation and examples browser" vmid="og:description"><meta data-n-head="ssr" property="og:title" content="opencvExample | examples | ofDocs" vmid="og:title"><meta data-n-head="ssr" property="og:image" content="/files/images/ofw-logo.png" vmid="og:image"><link rel="preload" href="/_nuxt/1222c887b819d0202cfa.js" as="script"><link rel="preload" href="/_nuxt/e2974c46edd15e353a99.js" as="script"><link rel="preload" href="/_nuxt/fe12c0cb7395fa1032f4.css" as="style"><link rel="preload" href="/_nuxt/f8d94d1c92ade1d8a6da.js" as="script"><link rel="preload" href="/_nuxt/f3151c6e69ccf58ccdfd.css" as="style"><link rel="preload" href="/_nuxt/c01572c3f985d7f6c287.js" as="script"><link rel="preload" href="/_nuxt/21c4d0f9583096394838.css" as="style"><link rel="preload" href="/_nuxt/adc32956be059d7527f6.js" as="script"><link rel="stylesheet" href="/_nuxt/fe12c0cb7395fa1032f4.css"><link rel="stylesheet" href="/_nuxt/f3151c6e69ccf58ccdfd.css"><link rel="stylesheet" href="/_nuxt/21c4d0f9583096394838.css">
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div id="app" class="unknown"><div id="menu"><h1 class="of"><div class="inner"><span><a href="/" class="nuxt-link-active"><div class="txt"><span class="docs f7 questrial">ofDocs </span><span class="version">0.11.0</span></div></a></span></div></h1><div id="search"><div class="inner"><div class="field text"><div class="field-inner"><svg viewbox="0 0 36 36" x="0px" y="0px" enable-background="new 0 0 36 36" xml:space="preserve"><path d="M35.525,31.228l-8.88-8.882c1.444-2.238,2.298-4.895,2.298-7.752c0-7.909-6.438-14.343-14.346-14.343						c-7.911,0-14.343,6.434-14.343,14.343c0,7.911,6.433,14.344,14.343,14.344c2.856,0,5.513-0.849,7.752-2.294l8.88,8.88						c0.295,0.297,0.782,0.297,1.076,0l3.22-3.221C35.824,32.008,35.824,31.523,35.525,31.228z M4.81,14.593						c0-5.396,4.391-9.788,9.788-9.788c5.398,0,9.787,4.392,9.787,9.788c0,5.398-4.389,9.789-9.787,9.789						C9.2,24.382,4.81,19.991,4.81,14.593z"></path></svg><!----><div class="text-wrapper"><input id="search_field" name="search_field" placeholder="Search (Alt+F)" autocomplete="off" tabindex="0"></div><!----><!----></div></div></div><div id="results" class="mt1"></div></div><div id="lists" class="menu-inner mt1"><div class="inner"><div class="item documentation"><a href="/documentation/" title="/documentation/"><i class="ico" style="display:none"></i><span>documentation</span><span style="display:none">documentation</span></a><!----></div><div class="item examples"><a href="/examples/" title="/examples/" class="nuxt-link-active"><i class="ico" style="display:none"></i><span>examples</span><span style="display:none">examples</span></a><div class="list"><div class="item 3d"><a href="/examples/3d/" title="/examples/3d/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>3d</span></a><!----></div><div class="item android"><a href="/examples/android/" title="/examples/android/"><i class="ico" style="display:none">android</i><span style="display:none"></span><span>android</span></a><!----></div><div class="item communication"><a href="/examples/communication/" title="/examples/communication/"><i class="ico" style="display:none">language</i><span style="display:none"></span><span>communication</span></a><!----></div><div class="item computer_vision"><a href="/examples/computer_vision/" title="/examples/computer_vision/" class="nuxt-link-active"><i class="ico" style="display:none">remove_red_eye</i><span style="display:none"></span><span>computer_vision</span></a><div class="list"><div class="item kinectExample"><a href="/examples/computer_vision/kinectExample/" title="/examples/computer_vision/kinectExample/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>kinectExample</span></a><!----></div><div class="item opencvExample"><a href="/examples/computer_vision/opencvExample/" title="/examples/computer_vision/opencvExample/" class="nuxt-link-exact-active nuxt-link-active"><i class="ico" style="display:none"></i><span style="display:none"></span><span>opencvExample</span></a><div class="list"></div></div><div class="item opencvHaarFinderExample"><a href="/examples/computer_vision/opencvHaarFinderExample/" title="/examples/computer_vision/opencvHaarFinderExample/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>opencvHaarFinderExample</span></a><!----></div></div></div><div class="item events"><a href="/examples/events/" title="/examples/events/"><i class="ico" style="display:none">question_answer</i><span style="display:none"></span><span>events</span></a><!----></div><div class="item gl"><a href="/examples/gl/" title="/examples/gl/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>gl</span></a><!----></div><div class="item gles"><a href="/examples/gles/" title="/examples/gles/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>gles</span></a><!----></div><div class="item graphics"><a href="/examples/graphics/" title="/examples/graphics/"><i class="ico" style="display:none">category</i><span style="display:none"></span><span>graphics</span></a><!----></div><div class="item gui"><a href="/examples/gui/" title="/examples/gui/"><i class="ico" style="display:none">tune</i><span style="display:none"></span><span>gui</span></a><!----></div><div class="item input_output"><a href="/examples/input_output/" title="/examples/input_output/"><i class="ico" style="display:none">flash_on</i><span style="display:none"></span><span>input_output</span></a><!----></div><div class="item ios"><a href="/examples/ios/" title="/examples/ios/"><i class="ico" style="display:none">phone_iphone</i><span style="display:none"></span><span>ios</span></a><!----></div><div class="item math"><a href="/examples/math/" title="/examples/math/"><i class="ico" style="display:none">border_clear</i><span style="display:none"></span><span>math</span></a><!----></div><div class="item shader"><a href="/examples/shader/" title="/examples/shader/"><i class="ico" style="display:none">waves</i><span style="display:none"></span><span>shader</span></a><!----></div><div class="item sound"><a href="/examples/sound/" title="/examples/sound/"><i class="ico" style="display:none">volume_up</i><span style="display:none"></span><span>sound</span></a><!----></div><div class="item strings"><a href="/examples/strings/" title="/examples/strings/"><i class="ico" style="display:none">text_format</i><span style="display:none"></span><span>strings</span></a><!----></div><div class="item templates"><a href="/examples/templates/" title="/examples/templates/"><i class="ico" style="display:none">amp_stories</i><span style="display:none"></span><span>templates</span></a><!----></div><div class="item threads"><a href="/examples/threads/" title="/examples/threads/"><i class="ico" style="display:none">texture</i><span style="display:none"></span><span>threads</span></a><!----></div><div class="item tvOS"><a href="/examples/tvOS/" title="/examples/tvOS/"><i class="ico" style="display:none">live_tv</i><span style="display:none"></span><span>tvOS</span></a><!----></div><div class="item video"><a href="/examples/video/" title="/examples/video/"><i class="ico" style="display:none">videocam</i><span style="display:none"></span><span>video</span></a><!----></div><div class="item windowing"><a href="/examples/windowing/" title="/examples/windowing/"><i class="ico" style="display:none">border_all</i><span style="display:none"></span><span>windowing</span></a><!----></div></div></div><div class="item openframeworks"><a href="/openframeworks/" title="/openframeworks/"><i class="ico" style="display:none"></i><span>openFrameworks</span><span style="display:none">openframeworks</span></a><!----></div><div class="item addons"><a href="/addons/" title="/addons/"><i class="ico" style="display:none">extension</i><span>addons</span><span style="display:none">addons</span></a><!----></div><div class="item guides"><a href="/guides/" title="/guides/"><i class="ico" style="display:none"></i><span>guides</span><span style="display:none">guides</span></a><!----></div></div></div></div><div id="document"><div id="renderer" class="main"><div absolute="/Users/Gilbert/Code/openFrameworks/examples/computer_vision/opencvExample" dir="../examples/computer_vision" route="/examples/computer_vision/opencvExample/" ext="" type="folder" id="727" children="728,729,730" parent="723" siblings="" translations="[object Object]" class="doc-header"><div class="doc-header-inner"><div class="inner"><div class="mt2 mb2"><span class="breadcrumbs"><span class="crumb"><a href="/" class="pink nuxt-link-active">ofDocs</a><span class="chevron right"></span></span><span class="crumb"><a href="/examples/" class="pink nuxt-link-active">examples </a><!----><span class="chevron right"></span></span><span class="crumb"><a href="/examples/computer_vision/" class="pink nuxt-link-active">computer_vision </a><!----><span class="chevron right"></span></span><span class="crumb"><!----><span class="link selector"><span>opencvExample </span><span class="chevron bottom"></span><select><option value="/examples/computer_vision/kinectExample/">kinectExample</option><option value="/examples/computer_vision/opencvExample/">opencvExample</option><option value="/examples/computer_vision/opencvHaarFinderExample/">opencvHaarFinderExample</option></select></span><!----></span></span></div></div></div></div><div class="editable-wrapper"><div class="header inner"><h1 class="page-title mb4 questrial"><span class="f7"><!----><span>opencvExample </span></span><span class="f3"></span></h1><div class="actions"><a href="/about/contribute/" class="button"><i class="ico">edit</i><span>Edit</span></a></div></div><div class="rendered"><div raw="# About opencvExample

![Screenshot of opencvExample](opencvExample.png)

### Learning Objectives

OpenCV is a powerful open-source library for image processing and computer vision. This example demonstrates one particularly common workflow in new-media art: performing *background subtraction*, *blob detection* and *contour tracing*. This is immensely useful for locating objects or people that have entered a scene!

After studying this example, you'll understand how to:

* Obtain video from a camera or stored file
* Use that video as the basis for image processing operations with OpenCV, including image arithmetic
* Extract blobs and their contours from background subtraction, a common workflow in computer vision applications.


### Expected Behavior

When launching this app, you'll see a window that displays five different stages in processing a video.

1. In the upper-left is the raw, unmodified video of a hand creating a shadow. Although it's not obvious, this is a color video (that happens to be showing a mostly black-and-white scene). After reading the hand video from its source file (using an `ofVideoPlayer`), this video is stored in `colorImg`, an `ofxCvColorImage`.
2. In the upper-right of the display is the same video, converted to grayscale. Here it is stored in the `grayImage` object, which is an instance of an `ofxCvGrayscaleImage`. It's easy to miss the grayscale conversion; it's done implicitly in the assignment `grayImage = colorImg;` (line 48 in the ofApp.cpp file) using operator overloading of the `=` sign. In this example, all of the subsequent image processing is done with grayscale (rather than color) images.
3. In the middle-left is a view of the *background image*. This is a grayscale image of the scene captured when the video first started playing, before the hand entered the frame. (See line 48 of the ofApp.cpp file.)
4. In the middle-right is an image that shows the *thresholded absolute difference* between the current frame and the background frame. This image has been *binarized*, meaning that pixel values are either black (0) or white (255). The white pixels represent regions that are significantly different from the background: the hand!
5. In the bottom right, an `ofxCvContourFinder` has been tasked to `findContours()` in the binarized image. It does this by identifying blobs of white pixels that meet certain area requirements -- and then tracing the contours of those blobs into an `ofxCvBlob` outline of (x,y) points. The app shows the contour of each blob in cyan, and also shows the bounding rectangle of those points in magenta. *Note:* The contour is a vector-based representation, and can be used for all sorts of further geometric play....

There are a few user-modifiable settings in this app:

* Pressing the `space` bar will capture a fresh image of the background.
* Pressing the `+` and `-` keys will adjust the threshold used in the absolute differencing operation. The greater the threshold value, the more different a pixel needs to be from the background in order to be considered part of the &#34;foreground&#34;.

**One more thing.** In line 7 of the `ofApp.h` file, you'll see the following line commented out:

```cpp
//#define _USE_LIVE_VIDEO
```
 If you uncomment this line, the app will use your computer's built-in webcam instead of a stored video file! It accomplishes this by swapping out the `ofVideoPlayer` with an `ofVideoGrabber`.


### Other classes used in this file

This example links against the `ofxOpenCv` core addon. It uses the following classes from that addon:

* [ofxCvColorImage](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvColorImage/)
* [ofxCvGrayscaleImage](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvGrayscaleImage/)
* [ofxCvContourFinder](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvContourFinder/)
* [ofxCvBlob](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvBlob/) *(used implicitly)*

In addition, this example uses the following classes to access  video from a live camera and/or a pre-stored file:

* [ofVideoPlayer](http://openframeworks.cc/documentation/video/ofVideoPlayer/)
* [ofVideoGrabber](http://openframeworks.cc/documentation/video/ofVideoGrabber/)
" type="folder" static="true" class="list-page"><div id="list-body" class="inner"><div class="markdown mb4"><div class="html"><h1>About opencvExample</h1>
<p><img src="opencvExample.png" alt="Screenshot of opencvExample"></p>
<h3>Learning Objectives</h3>
<p>OpenCV is a powerful open-source library for image processing and computer vision. This example demonstrates one particularly common workflow in new-media art: performing <em>background subtraction</em>, <em>blob detection</em> and <em>contour tracing</em>. This is immensely useful for locating objects or people that have entered a scene!</p>
<p>After studying this example, you'll understand how to:</p>
<ul>
<li>Obtain video from a camera or stored file</li>
<li>Use that video as the basis for image processing operations with OpenCV, including image arithmetic</li>
<li>Extract blobs and their contours from background subtraction, a common workflow in computer vision applications.</li>
</ul>
<h3>Expected Behavior</h3>
<p>When launching this app, you'll see a window that displays five different stages in processing a video.</p>
<ol>
<li>In the upper-left is the raw, unmodified video of a hand creating a shadow. Although it's not obvious, this is a color video (that happens to be showing a mostly black-and-white scene). After reading the hand video from its source file (using an <code>ofVideoPlayer</code>), this video is stored in <code>colorImg</code>, an <code>ofxCvColorImage</code>.</li>
<li>In the upper-right of the display is the same video, converted to grayscale. Here it is stored in the <code>grayImage</code> object, which is an instance of an <code>ofxCvGrayscaleImage</code>. It's easy to miss the grayscale conversion; it's done implicitly in the assignment <code>grayImage <span class="token operator">=</span> colorImg<span class="token punctuation">;</span></code> (line 48 in the ofApp.cpp file) using operator overloading of the <code><span class="token operator">=</span></code> sign. In this example, all of the subsequent image processing is done with grayscale (rather than color) images.</li>
<li>In the middle-left is a view of the <em>background image</em>. This is a grayscale image of the scene captured when the video first started playing, before the hand entered the frame. (See line 48 of the ofApp.cpp file.)</li>
<li>In the middle-right is an image that shows the <em>thresholded absolute difference</em> between the current frame and the background frame. This image has been <em>binarized</em>, meaning that pixel values are either black (0) or white (255). The white pixels represent regions that are significantly different from the background: the hand!</li>
<li>In the bottom right, an <code>ofxCvContourFinder</code> has been tasked to <code><span class="token function">findContours</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code> in the binarized image. It does this by identifying blobs of white pixels that meet certain area requirements -- and then tracing the contours of those blobs into an <code>ofxCvBlob</code> outline of (x,y) points. The app shows the contour of each blob in cyan, and also shows the bounding rectangle of those points in magenta. <em>Note:</em> The contour is a vector-based representation, and can be used for all sorts of further geometric play....</li>
</ol>
<p>There are a few user-modifiable settings in this app:</p>
<ul>
<li>Pressing the <code>space</code> bar will capture a fresh image of the background.</li>
<li>Pressing the <code><span class="token operator">+</span></code> and <code><span class="token operator">-</span></code> keys will adjust the threshold used in the absolute differencing operation. The greater the threshold value, the more different a pixel needs to be from the background in order to be considered part of the "foreground".</li>
</ul>
<p><strong>One more thing.</strong> In line 7 of the <code>ofApp<span class="token punctuation">.</span>h</code> file, you'll see the following line commented out:</p>
<pre><code><span class="token comment" spellcheck="true">//#define _USE_LIVE_VIDEO</span>
</code></pre>
<p>If you uncomment this line, the app will use your computer's built-in webcam instead of a stored video file! It accomplishes this by swapping out the <code>ofVideoPlayer</code> with an <code>ofVideoGrabber</code>.</p>
<h3>Other classes used in this file</h3>
<p>This example links against the <code>ofxOpenCv</code> core addon. It uses the following classes from that addon:</p>
<ul>
<li><a href="http://openframeworks.cc/documentation/ofxOpenCv/ofxCvColorImage/">ofxCvColorImage</a></li>
<li><a href="http://openframeworks.cc/documentation/ofxOpenCv/ofxCvGrayscaleImage/">ofxCvGrayscaleImage</a></li>
<li><a href="http://openframeworks.cc/documentation/ofxOpenCv/ofxCvContourFinder/">ofxCvContourFinder</a></li>
<li><a href="http://openframeworks.cc/documentation/ofxOpenCv/ofxCvBlob/">ofxCvBlob</a> <em>(used implicitly)</em></li>
</ul>
<p>In addition, this example uses the following classes to access  video from a live camera and/or a pre-stored file:</p>
<ul>
<li><a href="http://openframeworks.cc/documentation/video/ofVideoPlayer/">ofVideoPlayer</a></li>
<li><a href="http://openframeworks.cc/documentation/video/ofVideoGrabber/">ofVideoGrabber</a></li>
</ul>
</div></div><div class="directory"><div class="markdown"><hr></div><div class="columns"><div class="column mb2"><div class="item recursive-header src"><a href="/examples/computer_vision/opencvExample/src/" title="/examples/computer_vision/opencvExample/src/"><i class="ico" style="display:none"></i><span style="display:none"></span><span>src</span></a><div class="list"><div class="item main.cpp"><a href="/examples/computer_vision/opencvExample/src/main_cpp" title="/examples/computer_vision/opencvExample/src/main.cpp"><i class="ico" style="display:none"></i><span style="display:none"></span><span>main.cpp</span></a><div class="list"></div></div><div class="item ofApp.cpp"><a href="/examples/computer_vision/opencvExample/src/ofApp_cpp" title="/examples/computer_vision/opencvExample/src/ofApp.cpp"><i class="ico" style="display:none"></i><span style="display:none"></span><span>ofApp.cpp</span></a><div class="list"></div></div><div class="item ofApp.h"><a href="/examples/computer_vision/opencvExample/src/ofApp_h" title="/examples/computer_vision/opencvExample/src/ofApp.h"><i class="ico" style="display:none"></i><span style="display:none"></span><span>ofApp.h</span></a><div class="list"></div></div></div></div></div></div></div></div></div></div><textarea rows="0" class="markdown-editor" style="display:none"># About opencvExample

![Screenshot of opencvExample](opencvExample.png)

### Learning Objectives

OpenCV is a powerful open-source library for image processing and computer vision. This example demonstrates one particularly common workflow in new-media art: performing *background subtraction*, *blob detection* and *contour tracing*. This is immensely useful for locating objects or people that have entered a scene!

After studying this example, you'll understand how to:

* Obtain video from a camera or stored file
* Use that video as the basis for image processing operations with OpenCV, including image arithmetic
* Extract blobs and their contours from background subtraction, a common workflow in computer vision applications.


### Expected Behavior

When launching this app, you'll see a window that displays five different stages in processing a video.

1. In the upper-left is the raw, unmodified video of a hand creating a shadow. Although it's not obvious, this is a color video (that happens to be showing a mostly black-and-white scene). After reading the hand video from its source file (using an `ofVideoPlayer`), this video is stored in `colorImg`, an `ofxCvColorImage`.
2. In the upper-right of the display is the same video, converted to grayscale. Here it is stored in the `grayImage` object, which is an instance of an `ofxCvGrayscaleImage`. It's easy to miss the grayscale conversion; it's done implicitly in the assignment `grayImage = colorImg;` (line 48 in the ofApp.cpp file) using operator overloading of the `=` sign. In this example, all of the subsequent image processing is done with grayscale (rather than color) images.
3. In the middle-left is a view of the *background image*. This is a grayscale image of the scene captured when the video first started playing, before the hand entered the frame. (See line 48 of the ofApp.cpp file.)
4. In the middle-right is an image that shows the *thresholded absolute difference* between the current frame and the background frame. This image has been *binarized*, meaning that pixel values are either black (0) or white (255). The white pixels represent regions that are significantly different from the background: the hand!
5. In the bottom right, an `ofxCvContourFinder` has been tasked to `findContours()` in the binarized image. It does this by identifying blobs of white pixels that meet certain area requirements -- and then tracing the contours of those blobs into an `ofxCvBlob` outline of (x,y) points. The app shows the contour of each blob in cyan, and also shows the bounding rectangle of those points in magenta. *Note:* The contour is a vector-based representation, and can be used for all sorts of further geometric play....

There are a few user-modifiable settings in this app:

* Pressing the `space` bar will capture a fresh image of the background.
* Pressing the `+` and `-` keys will adjust the threshold used in the absolute differencing operation. The greater the threshold value, the more different a pixel needs to be from the background in order to be considered part of the "foreground".

**One more thing.** In line 7 of the `ofApp.h` file, you'll see the following line commented out:

```cpp
//#define _USE_LIVE_VIDEO
```
 If you uncomment this line, the app will use your computer's built-in webcam instead of a stored video file! It accomplishes this by swapping out the `ofVideoPlayer` with an `ofVideoGrabber`.


### Other classes used in this file

This example links against the `ofxOpenCv` core addon. It uses the following classes from that addon:

* [ofxCvColorImage](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvColorImage/)
* [ofxCvGrayscaleImage](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvGrayscaleImage/)
* [ofxCvContourFinder](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvContourFinder/)
* [ofxCvBlob](http://openframeworks.cc/documentation/ofxOpenCv/ofxCvBlob/) *(used implicitly)*

In addition, this example uses the following classes to access  video from a live camera and/or a pre-stored file:

* [ofVideoPlayer](http://openframeworks.cc/documentation/video/ofVideoPlayer/)
* [ofVideoGrabber](http://openframeworks.cc/documentation/video/ofVideoGrabber/)
</textarea></div></div></div></div></div></div><script defer src="/_nuxt/payloads/1583940179515/examples/computer_vision/opencvExample/payload.js"></script><script src="/_nuxt/1222c887b819d0202cfa.js" defer></script><script src="/_nuxt/adc32956be059d7527f6.js" defer></script><script src="/_nuxt/e2974c46edd15e353a99.js" defer></script><script src="/_nuxt/f8d94d1c92ade1d8a6da.js" defer></script><script src="/_nuxt/c01572c3f985d7f6c287.js" defer></script>
  </body>
</html>
