{"data":[{"page":{"entry":{"name":"README","filename":"README.md","absolute":"/Users/Gilbert/Code/openFrameworks/examples/ios/audioInputExample/README.md","path":"/examples/ios/audioInputExample/README","route":"/examples/ios/audioInputExample/README.md","dir":"../examples/ios/audioInputExample","ext":"md","type":"page","id":1218,"parent":1216,"breadcrumbs":[1216,1193,436],"translations":{},"siblings":[]},"description":{},"document":"<h2>#audioInputExample</h2>\n<p><img src=\"audioInputExample.gif\" alt=\"Screenshot of audioInputExample\"></p>\n<h3>Learning Objectives</h3>\n<p>This openFrameworks example is designed to demonstrate how to access, extract, and draw from your audio input's raw data.</p>\n<p>Studying the code behind this example will help you understand:</p>\n<ul>\n<li>How audio functions work independent from draw and update loop by observing the <code>audioIn</code> event.</li>\n<li>How raw audio information can be saved to a <code>buffer</code> array over time.</li>\n</ul>\n<h3>Expected Behavior</h3>\n<p>When launching this app, you should see</p>\n<ul>\n<li>Raw visual output of the audio buffer captured in the <code>buffer</code> array.</li>\n<li>Text that shows size of the buffer along with the count for the <code>audioIn</code> event.</li>\n</ul>\n<p>Instructions for use:</p>\n<ul>\n<li>make some noise or touch your microphone to see how sound manipulate the drawing.</li>\n<li>touch and hold the screen to turn up the volume</li>\n</ul>\n<h3>Classes used in this example</h3>\n<p>This Example uses the following classes:</p>\n<ul>\n<li><a href=\"http://openframeworks.cc/documentation/ofxiOS/\">ofxiOS</a> (for compiling openFrameworks to an Apple iOS device)</li>\n<li><code>ofSoundPlayer</code></li>\n<li><code>ofSoundStream</code></li>\n<li><code>ofSoundStreamSettings</code></li>\n</ul>\n","raw":"#audioInputExample\n--\n![Screenshot of audioInputExample](audioInputExample.gif)\n\n### Learning Objectives\n\nThis openFrameworks example is designed to demonstrate how to access, extract, and draw from your audio input's raw data.\n\nStudying the code behind this example will help you understand:\n\n* How audio functions work independent from draw and update loop by observing the ```audioIn``` event.\n* How raw audio information can be saved to a ```buffer``` array over time.\n\n\n### Expected Behavior\n\nWhen launching this app, you should see\n\n* Raw visual output of the audio buffer captured in the ```buffer``` array.\n* Text that shows size of the buffer along with the count for the ```audioIn``` event.\n\nInstructions for use:\n\n* make some noise or touch your microphone to see how sound manipulate the drawing.\n* touch and hold the screen to turn up the volume\n\n\n### Classes used in this example\n\nThis Example uses the following classes:\n\n* [ofxiOS](http://openframeworks.cc/documentation/ofxiOS/) (for compiling openFrameworks to an Apple iOS device)\n* ``ofSoundPlayer``\n* ``ofSoundStream``\n* ``ofSoundStreamSettings``\n","type":"page","static":true}}],"fetch":[]}