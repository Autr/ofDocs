{"data":[{"page":{"entry":{"name":"opencvExample","filename":"opencvExample","absolute":"/Users/Gilbert/Code/openFrameworks/examples/ios/opencvExample","path":"/examples/ios/opencvExample/","dir":"../examples/ios","route":"/examples/ios/opencvExample/","ext":"","type":"folder","id":1376,"children":[1377,1378,1379],"parent":1193,"breadcrumbs":[1193,436],"siblings":[],"translations":{}},"intro":{"name":"README","filename":"README.md","absolute":"/Users/Gilbert/Code/openFrameworks/examples/ios/opencvExample/README.md","path":"/examples/ios/opencvExample/README","route":"/examples/ios/opencvExample/README.md","dir":"../examples/ios/opencvExample","ext":"md","type":"page","id":1378,"parent":1376,"breadcrumbs":[1376,1193,436],"translations":{},"siblings":[]},"document":"<h1>About opencvExample</h1>\n<p><img src=\"opencvExample.png\" alt=\"Screenshot of opencvExample\"></p>\n<h3>Learning Objectives</h3>\n<p>OpenCV is a powerful open-source library for image processing and computer vision. This example demonstrates one particularly common workflow in new-media art: performing <em>background subtraction</em>, <em>blob detection</em> and <em>contour tracing</em>. This is immensely useful for locating objects or people that have entered a scene!</p>\n<p>After studying this example, you'll understand how to:</p>\n<ul>\n<li>Obtain video from a camera or stored file</li>\n<li>Use that video as the basis for image processing operations with OpenCV, including image arithmetic</li>\n<li>Extract blobs and their contours from background subtraction, a common workflow in computer vision applications.</li>\n</ul>\n<h3>Expected Behavior</h3>\n<p>When launching this app, you'll see a window that displays five different stages in processing a video.</p>\n<ol>\n<li>In the upper-left is the raw, unmodified video of a hand creating a shadow. Although it's not obvious, this is a color video (that happens to be showing a mostly black-and-white scene). After reading the hand video from its source file (using an <code>ofVideoPlayer</code>), this video is stored in <code>colorImg</code>, an <code>ofxCvColorImage</code>.</li>\n<li>In the upper-right of the display is the same video, converted to grayscale. Here it is stored in the <code>grayImage</code> object, which is an instance of an <code>ofxCvGrayscaleImage</code>. It's easy to miss the grayscale conversion; it's done implicitly in the assignment <code>grayImage <span class=\"token operator\">=</span> colorImg<span class=\"token punctuation\">;</span></code> (line 48 in the ofApp.cpp file) using operator overloading of the <code><span class=\"token operator\">=</span></code> sign. In this example, all of the subsequent image processing is done with grayscale (rather than color) images.</li>\n<li>In the middle-left is a view of the <em>background image</em>. This is a grayscale image of the scene captured when the video first started playing, before the hand entered the frame. (See line 48 of the ofApp.cpp file.)</li>\n<li>In the middle-right is an image that shows the <em>thresholded absolute difference</em> between the current frame and the background frame. This image has been <em>binarized</em>, meaning that pixel values are either black (0) or white (255). The white pixels represent regions that are significantly different from the background: the hand!</li>\n<li>In the bottom right, an <code>ofxCvContourFinder</code> has been tasked to <code><span class=\"token function\">findContours</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code> in the binarized image. It does this by identifying blobs of white pixels that meet certain area requirements -- and then tracing the contours of those blobs into an <code>ofxCvBlob</code> outline of (x,y) points. The app shows the contour of each blob in cyan, and also shows the bounding rectangle of those points in magenta. <em>Note:</em> The contour is a vector-based representation, and can be used for all sorts of further geometric play....</li>\n</ol>\n<p>There are a few user-modifiable settings in this app:</p>\n<ul>\n<li>Pressing the <code>space</code> bar will capture a fresh image of the background.</li>\n<li>Pressing the <code><span class=\"token operator\">+</span></code> and <code><span class=\"token operator\">-</span></code> keys will adjust the threshold used in the absolute differencing operation. The greater the threshold value, the more different a pixel needs to be from the background in order to be considered part of the &quot;foreground&quot;.</li>\n</ul>\n<p><strong>One more thing.</strong> In line 7 of the <code>ofApp<span class=\"token punctuation\">.</span>h</code> file, you'll see the following line commented out:</p>\n<pre><code><span class=\"token comment\" spellcheck=\"true\">//#define _USE_LIVE_VIDEO\t</span>\n</code></pre>\n<p>If you uncomment this line, the app will use your computer's built-in webcam instead of a stored video file! It accomplishes this by swapping out the <code>ofVideoPlayer</code> with an <code>ofVideoGrabber</code>.</p>\n<h3>Other classes used in this file</h3>\n<p>This example links against the <code>ofxOpenCv</code> core addon. It uses the following classes from that addon:</p>\n<ul>\n<li><a href=\"http://openframeworks.cc/documentation/ofxOpenCv/ofxCvColorImage/\">ofxCvColorImage</a></li>\n<li><a href=\"http://openframeworks.cc/documentation/ofxOpenCv/ofxCvGrayscaleImage/\">ofxCvGrayscaleImage</a></li>\n<li><a href=\"http://openframeworks.cc/documentation/ofxOpenCv/ofxCvContourFinder/\">ofxCvContourFinder</a></li>\n<li><a href=\"http://openframeworks.cc/documentation/ofxOpenCv/ofxCvBlob/\">ofxCvBlob</a> <em>(used implicitly)</em></li>\n</ul>\n<p>In addition, this example uses the following classes to access  video from a live camera and/or a pre-stored file:</p>\n<ul>\n<li><a href=\"http://openframeworks.cc/documentation/video/ofVideoPlayer/\">ofVideoPlayer</a></li>\n<li><a href=\"http://openframeworks.cc/documentation/video/ofVideoGrabber/\">ofVideoGrabber</a></li>\n</ul>\n","type":"folder"}}],"fetch":[]}